{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jonathasarruda/gnn-polymer-predictor?scriptVersionId=247704609\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"82de942a","metadata":{"_cell_guid":"6eefc3b6-5d11-4c8f-9915-f705a1af996d","_uuid":"35b11b65-a46c-4c2d-ab1a-01f61955fe7e","collapsed":false,"execution":{"iopub.execute_input":"2025-06-27T16:37:24.913697Z","iopub.status.busy":"2025-06-27T16:37:24.913379Z","iopub.status.idle":"2025-06-27T16:37:30.609042Z","shell.execute_reply":"2025-06-27T16:37:30.607989Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":5.701575,"end_time":"2025-06-27T16:37:30.610879","exception":false,"start_time":"2025-06-27T16:37:24.909304","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Arquivos disponíveis em /kaggle/input:\n","/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv\n","/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\n","/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\n","\n","Primeiras linhas do dataset de treino:\n","        id                                             SMILES  Tg       FFV  \\\n","0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n","1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n","2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n","3  519416  *Nc1ccc(-c2c(-c3ccc(C)cc3)c(-c3ccc(C)cc3)c(N*)... NaN  0.387324   \n","4  539187  *Oc1ccc(OC(=O)c2cc(OCCCCCCCCCOCC3CCCN3c3ccc([N... NaN  0.355470   \n","\n","         Tc  Density  Rg  \n","0  0.205667      NaN NaN  \n","1       NaN      NaN NaN  \n","2       NaN      NaN NaN  \n","3       NaN      NaN NaN  \n","4       NaN      NaN NaN  \n","\n","Informações gerais do dataset:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7973 entries, 0 to 7972\n","Data columns (total 7 columns):\n"," #   Column   Non-Null Count  Dtype  \n","---  ------   --------------  -----  \n"," 0   id       7973 non-null   int64  \n"," 1   SMILES   7973 non-null   object \n"," 2   Tg       511 non-null    float64\n"," 3   FFV      7030 non-null   float64\n"," 4   Tc       737 non-null    float64\n"," 5   Density  613 non-null    float64\n"," 6   Rg       614 non-null    float64\n","dtypes: float64(5), int64(1), object(1)\n","memory usage: 436.2+ KB\n","\n","Valores ausentes por coluna:\n"," id            0\n","SMILES        0\n","Tg         7462\n","FFV         943\n","Tc         7236\n","Density    7360\n","Rg         7359\n","dtype: int64\n","\n","Estatísticas descritivas:\n","                  id          Tg          FFV          Tc     Density  \\\n","count  7.973000e+03  511.000000  7030.000000  737.000000  613.000000   \n","mean   1.080050e+09   96.452314     0.367212    0.256334    0.985484   \n","std    6.218241e+08  111.228279     0.029609    0.089538    0.146189   \n","min    8.781700e+04 -148.029738     0.226992    0.046500    0.748691   \n","25%    5.376641e+08   13.674509     0.349549    0.186000    0.890243   \n","50%    1.079079e+09   74.040183     0.364264    0.236000    0.948193   \n","75%    1.621708e+09  161.147595     0.380790    0.330500    1.062096   \n","max    2.147438e+09  472.250000     0.777097    0.524000    1.840999   \n","\n","               Rg  \n","count  614.000000  \n","mean    16.419787  \n","std      4.608640  \n","min      9.728355  \n","25%     12.540328  \n","50%     15.052194  \n","75%     20.411067  \n","max     34.672906  \n","\n","Estatísticas individuais das variáveis alvo:\n","\n","Tg:\n","count    511.000000\n","mean      96.452314\n","std      111.228279\n","min     -148.029738\n","25%       13.674509\n","50%       74.040183\n","75%      161.147595\n","max      472.250000\n","Name: Tg, dtype: float64\n","\n","FFV:\n","count    7030.000000\n","mean        0.367212\n","std         0.029609\n","min         0.226992\n","25%         0.349549\n","50%         0.364264\n","75%         0.380790\n","max         0.777097\n","Name: FFV, dtype: float64\n","\n","Tc:\n","count    737.000000\n","mean       0.256334\n","std        0.089538\n","min        0.046500\n","25%        0.186000\n","50%        0.236000\n","75%        0.330500\n","max        0.524000\n","Name: Tc, dtype: float64\n","\n","Density:\n","count    613.000000\n","mean       0.985484\n","std        0.146189\n","min        0.748691\n","25%        0.890243\n","50%        0.948193\n","75%        1.062096\n","max        1.840999\n","Name: Density, dtype: float64\n","\n","Rg:\n","count    614.000000\n","mean      16.419787\n","std        4.608640\n","min        9.728355\n","25%       12.540328\n","50%       15.052194\n","75%       20.411067\n","max       34.672906\n","Name: Rg, dtype: float64\n","\n","Matriz de correlação entre as variáveis alvo:\n","                Tg       FFV        Tc   Density        Rg\n","Tg       1.000000       NaN  0.033300  0.235291  0.180072\n","FFV           NaN  1.000000  0.149878 -0.214185  0.053396\n","Tc       0.033300  0.149878  1.000000 -0.488476  0.554758\n","Density  0.235291 -0.214185 -0.488476  1.000000  0.091138\n","Rg       0.180072  0.053396  0.554758  0.091138  1.000000\n","\n","Total de SMILES únicos: 7973\n","\n","Número de SMILES duplicados: 0\n","\n","Estatísticas do comprimento dos SMILES:\n"," count    7973.000000\n","mean       58.353317\n","std        33.399405\n","min         3.000000\n","25%        33.000000\n","50%        52.000000\n","75%        77.000000\n","max       306.000000\n","Name: smiles_length, dtype: float64\n","\n","5 menores SMILES:\n","      SMILES  smiles_length\n","4442    *C*              3\n","3682   *CO*              4\n","5730   *CS*              4\n","2239  *CCN*              5\n","4141  *CCS*              5\n","\n","5 maiores SMILES:\n","                                                  SMILES  smiles_length\n","6840  *c1cc(C(c2ccc(OCc3cc(OCCN(C)c4ccc(C=CC5=CC(=C(...            306\n","5110  *c1cc(C(c2ccc(OCCN(C)c3ccc(C=CC4=CC(=C(C#N)C(=...            263\n","2077  *c1ccc(Oc2ccc(-c3nc4cc(Oc5ccc(NC(=O)c6ccc7c(c6...            243\n","2353  *C=C(C#N)c1ccc(-c2ccc(C=CC3=CC(=C(C#N)C#N)C=C(...            217\n","3131  *c1cc(C(c2ccc(OCCN(C)c3ccc(C=CC4=CC(=C(C#N)C(=...            217\n","\n","Colunas numéricas detectadas automaticamente (ordem preservada):\n"," ['num_branches', 'num_double_bonds', 'num_triple_bonds', 'num_ring_closures', 'num_aromatic_atoms', 'num_aliphatic_atoms', 'C', 'O', 'N', 'S', 'F', 'Cl', 'Br', 'I', 'P', 'num_atoms_total', 'num_atoms_unique']\n","\n","X_test shape: (3, 17)\n","y_test shape: (3,)\n"]}],"source":["# EDA, pré-processamento e engenharia — dados do MVP com automação e reprodutibilidade\n","# EDA, preprocesamiento e ingeniería — datos del MVP con automatización y reproducibilidad\n","# EDA, предварительная обработка и инженерия — данные MVP с автоматизацией и воспроизводимостью\n","# EDA, preprocessing and engineering — MVP data with automation and reproducibility\n","\n","import os\n","import re\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","import joblib\n","from pandas.api.types import is_numeric_dtype\n","import warnings\n","\n","# Ignorar warnings RuntimeWarning | Ignorar advertencias RuntimeWarning | Игнорировать предупреждения RuntimeWarning | Ignore RuntimeWarning warnings\n","warnings.filterwarnings('ignore', category=RuntimeWarning)\n","\n","# Listar arquivos em /kaggle/input | Listar archivos en /kaggle/input | Список файлов в /kaggle/input | List files in /kaggle/input\n","print(\"Arquivos disponíveis em /kaggle/input:\")\n","for root, _, files in os.walk('/kaggle/input'):\n","    for f in files:\n","        print(os.path.join(root, f))\n","\n","# Ler CSV treino | Leer CSV entrenamiento | Чтение CSV обучения | Read train CSV\n","train = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n","\n","# Ler CSV teste | Leer CSV prueba | Чтение CSV теста | Read test CSV\n","test = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n","\n","# Ler CSV submissão | Leer CSV submission | Чтение CSV сабмишн | Read submission CSV\n","submission = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')\n","\n","# Mostrar primeiras linhas treino | Mostrar primeras filas entrenamiento | Показать первые строки обучения | Show first train rows\n","print(\"\\nPrimeiras linhas do dataset de treino:\\n\", train.head())\n","\n","# Info geral dataframe | Info general del dataframe | Общая информация о датафрейме | General dataframe info\n","print(\"\\nInformações gerais do dataset:\")\n","train.info()\n","\n","# Contar valores ausentes | Contar valores faltantes | Подсчет пропущенных значений | Count missing values\n","print(\"\\nValores ausentes por coluna:\\n\", train.isnull().sum())\n","\n","# Estatísticas descritivas | Estadísticas descriptivas | Описательная статистика | Descriptive statistics\n","print(\"\\nEstatísticas descritivas:\\n\", train.describe())\n","\n","target_cols = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n","\n","# Estatísticas variáveis alvo | Estadísticas variables objetivo | Статистика целевых переменных | Target variables statistics\n","print(\"\\nEstatísticas individuais das variáveis alvo:\")\n","for c in target_cols:\n","    print(f\"\\n{c}:\\n{train[c].describe()}\")\n","\n","# Matriz correlação alvo | Matriz correlación objetivo | Корреляционная матрица целей | Target correlation matrix\n","print(\"\\nMatriz de correlação entre as variáveis alvo:\\n\", train[target_cols].corr())\n","\n","# Contar SMILES únicos | Contar SMILES únicos | Подсчет уникальных SMILES | Count unique SMILES\n","print(\"\\nTotal de SMILES únicos:\", train['SMILES'].nunique())\n","\n","# Encontrar SMILES duplicados | Encontrar duplicados SMILES | Поиск дубликатов SMILES | Find duplicate SMILES\n","duplicates = train[train.duplicated('SMILES')]\n","print(f\"\\nNúmero de SMILES duplicados: {len(duplicates)}\")\n","if not duplicates.empty:\n","    print(duplicates.head())\n","\n","# Criar coluna comprimento SMILES | Crear columna longitud SMILES | Создать колонку длины SMILES | Create SMILES length column\n","train['smiles_length'] = train['SMILES'].str.len()\n","\n","# Estatísticas comprimento SMILES | Estadísticas longitud SMILES | Статистика длины SMILES | SMILES length statistics\n","print(\"\\nEstatísticas do comprimento dos SMILES:\\n\", train['smiles_length'].describe())\n","\n","# Mostrar 5 menores SMILES | Mostrar 5 SMILES más cortos | Показать 5 самых коротких SMILES | Show 5 shortest SMILES\n","print(\"\\n5 menores SMILES:\\n\", train.nsmallest(5, 'smiles_length')[['SMILES','smiles_length']])\n","\n","# Mostrar 5 maiores SMILES | Mostrar 5 SMILES más largos | Показать 5 самых длинных SMILES | Show 5 longest SMILES\n","print(\"\\n5 maiores SMILES:\\n\", train.nlargest(5, 'smiles_length')[['SMILES','smiles_length']])\n","\n","# Extrair features SMILES | Extraer features SMILES | Извлечение признаков SMILES | Extract SMILES features\n","def smiles_robust_features(smiles):\n","    atom_counts = {\n","        'C': len(re.findall(r'C(?![a-z])', smiles)),\n","        'O': len(re.findall(r'O', smiles)),\n","        'N': len(re.findall(r'N(?![a-z])', smiles)),\n","        'S': len(re.findall(r'S(?![a-z])', smiles)),\n","        'F': len(re.findall(r'F', smiles)),\n","        'Cl': len(re.findall(r'Cl', smiles)),\n","        'Br': len(re.findall(r'Br', smiles)),\n","        'I': len(re.findall(r'I', smiles)),\n","        'P': len(re.findall(r'P', smiles)),\n","    }\n","    features = {\n","        'smiles_length': len(smiles),\n","        'num_branches': smiles.count('(') + smiles.count(')'),\n","        'num_double_bonds': smiles.count('='),\n","        'num_triple_bonds': smiles.count('#'),\n","        'num_ring_closures': len(re.findall(r'\\d', smiles)),\n","        'num_aromatic_atoms': len(re.findall(r'[bcnops]', smiles)),\n","        'num_aliphatic_atoms': len(re.findall(r'[BCNOPSFHI]', smiles)),\n","        **atom_counts,\n","    }\n","    features['num_atoms_total'] = sum(atom_counts.values())\n","    features['num_atoms_unique'] = sum(v > 0 for v in atom_counts.values())\n","    return pd.Series(features)\n","\n","# Aplicar features SMILES no treino | Aplicar features SMILES en entrenamiento | Применить признаки SMILES к обучению | Apply SMILES features to train\n","train = pd.concat([train, train['SMILES'].apply(smiles_robust_features)], axis=1)\n","\n","# Preencher NA variáveis alvo | Rellenar NA variables objetivo | Заполнить NA целевые переменные | Fill NA target variables\n","train[target_cols] = train[target_cols].fillna(train[target_cols].mean())\n","\n","exclude_cols = ['id', 'SMILES'] + target_cols\n","\n","# Selecionar colunas numéricas | Seleccionar columnas numéricas | Выбор числовых колонок | Select numeric columns\n","numerical_cols = [col for col in train.columns if col not in exclude_cols and is_numeric_dtype(train[col])]\n","print(\"\\nColunas numéricas detectadas automaticamente (ordem preservada):\\n\", numerical_cols)\n","\n","# Inicializar scaler | Inicializar scaler | Инициализировать scaler | Initialize scaler\n","scaler = StandardScaler()\n","\n","# Normalizar colunas numéricas | Normalizar columnas numéricas | Нормализовать числовые колонки | Normalize numeric columns\n","train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n","\n","# Salvar scaler | Guardar scaler | Сохранить scaler | Save scaler\n","joblib.dump(scaler, \"scaler.pkl\")\n","\n","# Extrair features SMILES teste | Extraer features SMILES test | Извлечь признаки SMILES теста | Extract SMILES features test\n","X_test_raw = test['SMILES'].apply(smiles_robust_features)\n","\n","# Ajustar ordem colunas teste | Ajustar orden columnas test | Согласовать порядок колонок теста | Align test columns order\n","X_test_raw = X_test_raw[numerical_cols]\n","\n","# Carregar scaler salvo | Cargar scaler guardado | Загрузить сохранённый scaler | Load saved scaler\n","scaler = joblib.load(\"scaler.pkl\")\n","\n","# Aplicar scaler no teste | Aplicar scaler en test | Применить scaler к тесту | Apply scaler to test\n","X_test = scaler.transform(X_test_raw)\n","\n","# Extrair ids teste | Extraer ids test | Извлечь id теста | Extract test ids\n","y_test = test['id'].values\n","\n","# Conferir shape X_test | Revisar forma X_test | Проверить размер X_test | Check X_test shape\n","print(\"\\nX_test shape:\", X_test.shape)\n","\n","# Conferir shape y_test | Revisar forma y_test | Проверить размер y_test | Check y_test shape\n","print(\"y_test shape:\", y_test.shape)"]},{"cell_type":"code","execution_count":2,"id":"8bb318dd","metadata":{"_cell_guid":"e41f50e0-7f68-4c15-88bb-b5d13ccd5355","_uuid":"c56b0289-9932-4819-9746-8b1210adc4e6","collapsed":false,"execution":{"iopub.execute_input":"2025-06-27T16:37:30.617889Z","iopub.status.busy":"2025-06-27T16:37:30.617557Z","iopub.status.idle":"2025-06-27T16:44:39.210717Z","shell.execute_reply":"2025-06-27T16:44:39.209526Z"},"jupyter":{"outputs_hidden":false},"papermill":{"duration":428.59911,"end_time":"2025-06-27T16:44:39.212761","exception":false,"start_time":"2025-06-27T16:37:30.613651","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Iniciando treinamento da GNN...\n","Epoch 001 | Loss: 2070.5767\n","Epoch 010 | Loss: 1671.3273\n","Epoch 020 | Loss: 526.1531\n","Epoch 030 | Loss: 399.2482\n","Epoch 040 | Loss: 334.5354\n","Epoch 050 | Loss: 299.4846\n","Epoch 060 | Loss: 276.0434\n","Epoch 070 | Loss: 259.0978\n","Epoch 080 | Loss: 249.9044\n","Epoch 090 | Loss: 240.9647\n","Epoch 100 | Loss: 232.7760\n","\n","Weighted MAE (wMAE) no conjunto de treino: 0.078748\n","\n","Arquivo de submissão salvo: submission.csv\n","\n","Prévia da submissão:\n","           id          Tg       FFV        Tc   Density         Rg\n","0  1109053969   50.814766  0.204257  0.196975  0.553252   8.851948\n","1  1422188626  109.132988  0.419343  0.279088  1.173885  18.439932\n","2  2032016830   87.554619  0.349316  0.251073  0.900305  15.131663\n"]}],"source":["# Modelo | Modelo | Модель | Model\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.preprocessing import StandardScaler\n","\n","# Caminho de dados | Ruta de datos | Путь к данным | Data path\n","train = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n","test = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n","submission = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv')\n","\n","# Alvos | Objetivos | Цели | Targets\n","target_cols = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n","\n","# Extração simples de features dos SMILES | Extracción de características | Извлечение признаков | Feature extraction\n","def smiles_robust_features(smiles):\n","    import re\n","    atom_counts = {\n","        'C': len(re.findall(r'C(?![a-z])', smiles)),\n","        'O': len(re.findall(r'O', smiles)),\n","        'N': len(re.findall(r'N(?![a-z])', smiles)),\n","        'S': len(re.findall(r'S(?![a-z])', smiles)),\n","        'F': len(re.findall(r'F', smiles)),\n","        'Cl': len(re.findall(r'Cl', smiles)),\n","        'Br': len(re.findall(r'Br', smiles)),\n","        'I': len(re.findall(r'I', smiles)),\n","        'P': len(re.findall(r'P', smiles)),\n","    }\n","    features = {\n","        'smiles_length': len(smiles),\n","        'num_branches': smiles.count('(') + smiles.count(')'),\n","        'num_double_bonds': smiles.count('='),\n","        'num_triple_bonds': smiles.count('#'),\n","        'num_ring_closures': len(re.findall(r'\\d', smiles)),\n","        'num_aromatic_atoms': len(re.findall(r'[bcnops]', smiles)),\n","        'num_aliphatic_atoms': len(re.findall(r'[BCNOPSFHI]', smiles)),\n","        **atom_counts,\n","    }\n","    features['num_atoms_total'] = sum(atom_counts.values())\n","    features['num_atoms_unique'] = sum(v > 0 for v in atom_counts.values())\n","    return pd.Series(features)\n","\n","# Aplicar features | Aplicar características | Применить признаки | Apply features\n","train_feats = train['SMILES'].apply(smiles_robust_features)\n","test_feats = test['SMILES'].apply(smiles_robust_features)\n","\n","# Preenchimento de alvos ausentes | Relleno de objetivos | Заполнение целей | Fill missing targets\n","train[target_cols] = train[target_cols].fillna(train[target_cols].mean())\n","\n","# Colunas numéricas | Columnas numéricas | Числовые признаки | Numerical columns\n","numerical_cols = train_feats.columns.tolist()\n","\n","# Normalização | Normalización | Нормализация | Normalization\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(train_feats[numerical_cols])\n","X_test = scaler.transform(test_feats[numerical_cols])\n","X_all = np.vstack([X_train, X_test])\n","\n","# Similaridade por cosseno | Similitud coseno | Косинусное сходство | Cosine similarity\n","threshold = 0.8\n","sim_matrix = cosine_similarity(X_all)\n","edges = np.array(np.nonzero(np.triu(sim_matrix, k=1) > threshold))\n","edges = np.hstack([edges, edges[::-1]])  # bidirecional\n","edge_index = torch.tensor(edges, dtype=torch.long)\n","\n","# GCN manual | GCN manual | Ручной GCN | Manual GCN\n","class ManualGCNLayer(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.linear = nn.Linear(in_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        row, col = edge_index\n","        deg = torch.bincount(row, minlength=x.size(0)).float()\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","        agg = torch.zeros_like(x)\n","        agg.index_add_(0, row, x[col] * norm.unsqueeze(1))\n","        return self.linear(agg)\n","\n","# Modelo simples GNN | GNN simple | Простая GNN | Simple GNN\n","class SimpleGNN(nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        self.gcn1 = ManualGCNLayer(in_channels, hidden_channels)\n","        self.relu = nn.ReLU()\n","        self.gcn2 = ManualGCNLayer(hidden_channels, hidden_channels)\n","        self.dropout = nn.Dropout(p=0.2)\n","        self.linear = nn.Linear(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        x = self.gcn1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.gcn2(x, edge_index)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.linear(x)\n","        return x\n","\n","# Dispositivo | Dispositivo | Устройство | Device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Tensores | Tensores | Тензоры | Tensors\n","x_all = torch.tensor(X_all, dtype=torch.float32).to(device)\n","y_train = train[target_cols].values\n","y_test = np.zeros((X_test.shape[0], len(target_cols)))\n","y_all = torch.tensor(np.vstack([y_train, y_test]), dtype=torch.float32).to(device)\n","\n","# Máscaras | Máscaras | Маски | Masks\n","n_train = X_train.shape[0]\n","train_mask = torch.zeros(x_all.size(0), dtype=torch.bool).to(device)\n","train_mask[:n_train] = True\n","test_mask = ~train_mask\n","edge_index = edge_index.to(device)\n","\n","# Instanciar modelo | Instanciar modelo | Инициализация | Instantiate model\n","model = SimpleGNN(\n","    in_channels=x_all.shape[1],\n","    hidden_channels=64,\n","    out_channels=len(target_cols)\n",").to(device)\n","\n","# Otimizador | Optimizador | Оптимизатор | Optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.MSELoss()\n","\n","# Treinamento | Entrenamiento | Обучение | Training\n","print(\"Iniciando treinamento da GNN...\")  # PT\n","\n","for epoch in range(1, 101):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(x_all, edge_index)\n","    loss = criterion(out[train_mask], y_all[train_mask])\n","    loss.backward()\n","    optimizer.step()\n","\n","    if epoch % 10 == 0 or epoch == 1:\n","        print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f}\")\n","\n","# wMAE | wMAE | wMAE | wMAE\n","def weighted_mae(y_true, y_pred):\n","    n_samples, n_targets = y_true.shape\n","    n_j = np.sum(~np.isnan(y_true), axis=0)\n","    R_j = np.nanmax(y_true, axis=0) - np.nanmin(y_true, axis=0)\n","    w_j = 1 / (np.sqrt(n_j) * R_j)\n","    w_j /= w_j.sum()\n","    mae_j = np.nanmean(np.abs(y_true - y_pred), axis=0)\n","    wmae = np.sum(w_j * mae_j)\n","    return wmae\n","\n","# Avaliação | Evaluación | Оценка | Evaluation\n","model.eval()\n","with torch.no_grad():\n","    train_preds = model(x_all, edge_index)[train_mask].cpu().numpy()\n","    y_train_true = y_all[train_mask].cpu().numpy()\n","\n","wmae_train = weighted_mae(y_train_true, train_preds)\n","print(f\"\\nWeighted MAE (wMAE) no conjunto de treino: {wmae_train:.6f}\")\n","\n","# Inferência | Inferencia | Предсказание | Inference\n","with torch.no_grad():\n","    predictions = model(x_all, edge_index)[test_mask].cpu().numpy()\n","\n","# Submissão | Envío | Сабмишн | Submission\n","submission = pd.DataFrame({'id': test['id']})\n","for i, col in enumerate(target_cols):\n","    submission[col] = predictions[:, i]\n","\n","submission.to_csv(\"submission.csv\", index=False)\n","print(\"\\nArquivo de submissão salvo: submission.csv\")\n","\n","# Prévia | Vista previa | Предпросмотр | Preview\n","print(\"\\nPrévia da submissão:\")\n","print(submission.head())"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":12609125,"sourceId":74608,"sourceType":"competition"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":443.616259,"end_time":"2025-06-27T16:44:42.10648","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-27T16:37:18.490221","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}