import os
import torch
import traceback
from gnn_polymer_predictor import SimpleGNN

print("ğŸ“ ConteÃºdo da pasta model:", os.listdir("model"))

class ModelService:
    def __init__(self):
        print("ğŸ” Iniciando carregamento do modelo...")

        checkpoint_path = "model/simple_gnn.pt"

        try:
            checkpoint = torch.load(checkpoint_path, map_location="cpu")
            print("âœ… Checkpoint carregado com sucesso")

            # Detecta formato do checkpoint
            if isinstance(checkpoint, dict) and "state_dict" in checkpoint:
                print("ğŸ“¦ Checkpoint contÃ©m metadados")
                in_channels = checkpoint.get("in_channels", 17)
                hidden_channels = checkpoint.get("hidden_channels", 64)
                out_channels = checkpoint.get("out_channels", 5)
                state_dict = checkpoint["state_dict"]
            else:
                print("ğŸ“¦ Checkpoint Ã© apenas state_dict")
                in_channels = 17
                hidden_channels = 64
                out_channels = 5
                state_dict = checkpoint

            print(f"ğŸ“ ParÃ¢metros detectados: in={in_channels}, hidden={hidden_channels}, out={out_channels}")

            # Cria o modelo
            self.model = SimpleGNN(in_channels, hidden_channels, out_channels)
            self.model.load_state_dict(state_dict)
            self.model.eval()

            print("âœ… Modelo carregado e pronto")

        except Exception as e:
            print("âŒ Erro ao carregar o modelo:")
            traceback.print_exc()
            raise e  # forÃ§a o Render a mostrar o erro e parar aqui

    def predict(self, x_all, edge_index, mask=None):
        with torch.no_grad():
            out = self.model(x_all, edge_index)

            # Retorna sÃ³ os nÃ³s selecionados
            if mask is not None:
                return out[mask].cpu().numpy()

            # Ou retorna todos os nÃ³s
            return out.cpu().numpy()
